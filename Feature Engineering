Feature engineering
 
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
There are no categorical features here.

#Combine features.
​
X_train['density'] = X_train['weight'].abs() / X_train['size'].abs()
X_test['density']  = X_test['weight'].abs() / X_test['size'].abs()
​
#X_train['sweetness/acidity'] = X_train['sweetness'].abs() / X_train['acidity'].abs()
#X_test['sweetness/acidity']  = X_test['sweetness'].abs() / X_test['acidity'].abs()
Outliers - Replacement by median.

class OutliersZScoreReplacer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        self.mean_std_median = list()
        for name in X.columns:
            mean   = X[name].mean()
            std    = X[name].std()
            median = X[name].median()
            self.mean_std_median.append((mean, std, median))
        return self
​
    def fit_transform(self, X, y=None):
        self.fit(X, y)
        return self.transform(X, y)
​
    def get_feature_names_out(self):
        pass
​
    def transform(self, X, y=None):
        std_unit = 3
        for index, name in enumerate(X.columns):
            mean    = self.mean_std_median[index][0]
            std     = self.mean_std_median[index][1]
            median  = self.mean_std_median[index][2]
            scores  = ((X[name] - mean) / std)
            filter_mask = ((scores < -std_unit) | (scores > std_unit))
            X.loc[filter_mask, name] = median
        return X
out = OutliersZScoreReplacer()
​
df_encoded = out.fit_transform(X_train)
X_train[df_encoded.columns] = df_encoded
​
df_encoded = out.transform(X_test)
X_test[df_encoded.columns] = df_encoded
#Drop 'a_id'.
​
X_train = X_train.drop('a_id', axis=1)
X_test  = X_test.drop('a_id', axis=1)
we're
#Although the dataset seems standardized we will standardize it again because we're not sure if it really is and I created new features.
​
std = StandardScaler()
X_train = std.fit_transform(X_train)
X_test  = std.transform(X_test)
#PolynomialFeatures
#Maybe if we train the models with a polynomial version of the dataset they score better.
​
pf = PolynomialFeatures(degree=2, include_bias=False)
X_train_poly = pf.fit_transform(X_train)
X_test_poly  = pf.transform(X_test)
