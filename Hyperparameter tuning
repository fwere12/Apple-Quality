params = {'hidden_layer_sizes':[(10,), (100, 10), (200, 100, 10), (300, 200, 100)],
          'activation': ['identity', 'logistic', 'tanh', 'relu'],
          'solver': ['sgd', 'adam'],
          'learning_rate_init': np.arange(0.0001, 1, 0.01),
          'learning_rate': ['constant', 'invscaling', 'adaptive'],
          'alpha': np.arange(0.0001, 1, 0.01),}

rs = RandomizedSearchCV(MLPClassifier(max_iter=500, early_stopping=True), params, n_iter=30, cv=5, scoring='accuracy', verbose=False)
rs.fit(X_train, y_train)

print(f'The best hyperparameters are: {rs.best_params_}')
model = rs.best_estimator_

#The best hyperparameters are: {'solver': 'sgd', 'learning_rate_init': 0.4401, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (300, 200, 100), 'alpha': 0.4001, 'activation': 'tanh'}

model.fit(X_train, y_train)
y_pred = model.predict(X_train)
print(classification_report(y_train, y_pred))

#output
precision    recall  f1-score   support

       False       0.95      0.94      0.95      1497
        True       0.94      0.96      0.95      1503

    accuracy                           0.95      3000
   macro avg       0.95      0.95      0.95      3000
weighted avg       0.95      0.95      0.95      3000


y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

#Output
precision    recall  f1-score   support

       False       0.94      0.93      0.94       499
        True       0.93      0.94      0.94       501

    accuracy                           0.94      1000
   macro avg       0.94      0.94      0.94      1000
weighted avg       0.94      0.94      0.94      1000

